\relax 
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Evolution of the blackjack learning network agent development from left-to right: Q-learning to double deep q learning (DDQN) in blue, experimental noisy DDQN in pink, A/B testing of actor-to-critic (A2C) DDQN and previous DDQN in green. Future proposed work is the combined LLM based A2C agent in yellow.}}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Problem Statement / Project Architecture}{2}{}\protected@file@percent }
\newlabel{sec:problem}{{2}{2}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Method(s) / System Design}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example of the Double Headed Deep Q-Learning (DDQN) Network Agent.}}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Example of the Noisy Double Headed Deep Q-Learning Network Agent.}}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Example of the Deep Actor-to-Critic Learning Network Agent.}}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Evaluation}{4}{}\protected@file@percent }
\newlabel{sec:eval}{{4}{4}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Evaluation of the learned strategy of the DDQN agent. The charts at the top use blue hue blocks indicate the chance to stand (more red) and the change to hit (more blue) the dealers card according to the player's or agents sum. The charts at the bottom use darker hue blocks to indicate more disagreement. The DDQN shows more ragged decision boundaries.}}{4}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Evaluation of the learned strategy of the A2C agent. The charts at the top use blue hue blocks indicate the chance to stand (more red) and the change to hit (more blue) the dealers card according to the player's or agents sum. The charts at the bottom use darker hue blocks to indicate more disagreement. The A2C shows more smooth decision boundaries.}}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{5}{}\protected@file@percent }
\bibstyle{IEEEtran}
\bibcite{pavlov1927}{1}
\bibcite{thorndike1911}{2}
\bibcite{skinner1938}{3}
\bibcite{markov1906}{4}
\bibcite{bellman1957}{5}
\bibcite{sutton1998}{6}
\bibcite{watkins1989}{7}
\bibcite{mnih2015}{8}
\bibcite{wang2016}{9}
\bibcite{schulman2017}{10}
\bibcite{konda1999}{11}
\bibcite{gymnasium}{12}
\bibcite{pytorch}{13}
\bibcite{agileRL}{14}
\bibcite{mnih2016}{15}
\bibcite{wang2020}{16}
\bibcite{vaswani2017}{17}
\bibcite{devlin2018}{18}
\@writefile{toc}{\contentsline {section}{References}{6}{}\protected@file@percent }
\gdef \@abspage@last{6}
